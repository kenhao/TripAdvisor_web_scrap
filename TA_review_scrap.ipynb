{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b34a32",
   "metadata": {},
   "source": [
    "## 3.此程式:\n",
    "最後一步爬取每個評論並儲存到csv中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4bad73",
   "metadata": {},
   "source": [
    "## Package loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7339c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv #This package lets us save data to a csv file\n",
    "from selenium import webdriver #The Selenium package we'll need\n",
    "import time #This package lets us pause execution for a bit\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e5beba",
   "metadata": {},
   "source": [
    "## Web driver setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110494ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_driver_setting():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-images')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument(\"--disable-javascript\")\n",
    "    # 無痕模式\n",
    "    options.add_argument('--incognito')\n",
    "    driver = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options=options)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb648e30",
   "metadata": {},
   "source": [
    "## Scraping function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2acb969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 獲得, locationId\n",
    "def get_ids_from_hotel_url(url):\n",
    "\n",
    "  url = url.split('-')\n",
    "\n",
    "  geo = url[1]\n",
    "\n",
    "  loc = url[2]\n",
    "\n",
    "  return (int(geo[1:]), int(loc[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d25e08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.get(\"https://www.tripadvisor.com/Hotel_Review-g60763-d8732904-Reviews-Edge_Hotel-New_York_City_New_York.html\")\n",
    "\n",
    "# time.sleep(2)\n",
    "# driver.find_element(By.XPATH, \".//div[contains(@data-test-target, 'expand-review')]\").click()\n",
    "# blocks = driver.find_elements(By.XPATH, '//div[@data-test-target=\"HR_CC_CARD\"]')\n",
    "# for block in blocks:\n",
    "#     # Grab date of stay\n",
    "#     # date_of_stay = block.find_element(By.XPATH, './/span[@class=\"teHYY _R Me S4 H3\"]').text.split(\":\")[1].strip()\n",
    "            \n",
    "#     # Grab trip and date type\n",
    "#     trip_date_element = block.find_elements(By.XPATH, './/div[@class=\"vTVDc\"]//span')\n",
    "#     # Initialize trip_type and date as 'NULL'\n",
    "#     trip_type = 'NULL'\n",
    "#     date_of_stay = 'NULL'\n",
    "#     # Loop through each span element and check for the class\n",
    "#     for span_element in trip_date_element:\n",
    "#         if 'TDKzw _R Me' in span_element.get_attribute('class'):\n",
    "#             trip_type = block.find_element(By.XPATH, './/span[@class=\"TDKzw _R Me\"]').text.split(\":\")[1].strip()\n",
    "#             break  # Found the trip type, no need to continue searching\n",
    "#     print(trip_type)\n",
    "    \n",
    "#     for span_element in trip_date_element:\n",
    "#         if 'teHYY _R Me S4 H3' in span_element.get_attribute('class'):\n",
    "#             date_of_stay = block.find_element(By.XPATH, './/span[@class=\"teHYY _R Me S4 H3\"]').text.split(\":\")[1].strip()\n",
    "#     print(date_of_stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c18e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = web_driver_setting()\n",
    "# driver.get('https://www.tripadvisor.com/Hotel_Review-g60763-d1733337-Reviews-Sutton_Court_Hotel_Residences-New_York_City_New_York.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c71621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver.get('https://www.tripadvisor.com/Hotel_Review-g60763-d1733337-Reviews-Sutton_Court_Hotel_Residences-New_York_City_New_York.html')\n",
    "# time.sleep(2)\n",
    "# reviews_numbers_element = driver.find_elements(By.XPATH, '//label[@class=\"Qukvo Vm _S\"]')\n",
    "# for r in reviews_numbers_element:\n",
    "#     language = r.find_element(By.XPATH, './/span[@class=\"ZmySZ q\"]').text\n",
    "#     print(language)\n",
    "#     if language == 'English':\n",
    "#         reviews_numbers_ele = r.find_element(By.XPATH, './/span[@class=\"POjZy\"]').text\n",
    "#         reviews_numbers = int(reviews_numbers_ele.strip('()'))\n",
    "#         break\n",
    "# print(reviews_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2db5503d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = web_driver_setting()\n",
    "# driver.get('https://www.tripadvisor.com/Hotel_Review-g60763-d8732904-Reviews-Edge_Hotel-New_York_City_New_York.html')\n",
    "# time.sleep(2)\n",
    "# blocks = driver.find_elements(By.XPATH, '//div[@data-test-target=\"HR_CC_CARD\"]')\n",
    "# for b in blocks:\n",
    "#     try:\n",
    "#         rhv = b.find_element(By.XPATH, './/span[@class=\"hVSKz S2 H2 Ch sJlxi\"]')\n",
    "        \n",
    "#         review_helpful_votes = rhv.text.split(' ')[0]\n",
    "#     except: \n",
    "#         review_helpful_votes = 0\n",
    "#     print(review_helpful_votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e180c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time.sleep(2)\n",
    "# language_numbers_element = driver.find_elements(By.XPATH, '//li[@class=\"ui_radio XpoVm\"]')\n",
    "# for r in language_numbers_element:\n",
    "#     language = r.find_element(By.XPATH, './/span[@class=\"ZmySZ q\"]').text\n",
    "#     print(language)\n",
    "#     if language == 'English':\n",
    "#         reviews_numbers_ele = r.find_element(By.XPATH, './/span[@class=\"POjZy\"]').text\n",
    "#         reviews_numbers = int(reviews_numbers_ele.strip('()'))\n",
    "#         break\n",
    "# print(reviews_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e059f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotel_review(driver, hotel_url):\n",
    "    #先取得LocationId和GeoID\n",
    "    geo, loc = get_ids_from_hotel_url(hotel_url)\n",
    "    \n",
    "    # 先和目標網頁建立連線\n",
    "    driver.get(hotel_url)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        # 爬取評論數量 \n",
    "        reviews_numbers_element = driver.find_elements(By.XPATH, '//label[@class=\"Qukvo Vm _S\"]')\n",
    "        for r in reviews_numbers_element:\n",
    "            language = r.find_element(By.XPATH, './/span[@class=\"ZmySZ q\"]').text\n",
    "            if language == 'English':\n",
    "                reviews_numbers_ele = r.find_element(By.XPATH, './/span[@class=\"POjZy\"]').text\n",
    "                reviews_numbers_text = reviews_numbers_ele.strip('()')\n",
    "                reviews_numbers = re.sub('[^0-9]', '', reviews_numbers_text)\n",
    "                break\n",
    "            \n",
    "        # 設定要爬取的頁面數量\n",
    "        if int(reviews_numbers)%10 == 0:\n",
    "            pages_to_scrape = int(reviews_numbers)/10\n",
    "        else:\n",
    "            pages_to_scrape = int(int(reviews_numbers)/10)+1\n",
    "        # 若評論數夠多，限制在10頁，最多爬100筆\n",
    "        if(pages_to_scrape > 10):\n",
    "            pages_to_scrape = 10\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        pages_to_scrape = 0\n",
    "\n",
    "    #儲存loop 跑的每筆資料\n",
    "    row_data = []\n",
    "\n",
    "    for i in range(pages_to_scrape):\n",
    "        # give the DOM time to load\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Click the \"expand review\" link to reveal the entire review.\n",
    "        driver.find_element(By.XPATH, \".//div[contains(@data-test-target, 'expand-review')]\").click()\n",
    "\n",
    "        # 尋找所有整個評論的評論區塊元素，return list\n",
    "        # profiles = driver.find_elements(By.XPATH, '//div[@class=\"IHLTq _Z o\"]')\n",
    "        # containers = driver.find_elements(By.XPATH, '//div[@data-test-target=\"reviews-tab\"]//div[@data-reviewid]')\n",
    "        # print(containers)\n",
    "        blocks = driver.find_elements(By.XPATH, '//div[@data-test-target=\"HR_CC_CARD\"]')\n",
    "\n",
    "        for block in blocks:\n",
    "            # Grab review ID\n",
    "            review_id = block.find_element(By.XPATH, \".//div[@class='WAllg _T']\").get_attribute(\"data-reviewid\")\n",
    "            \n",
    "            # Grab date\n",
    "            date = block.find_element(By.XPATH, './/div[@class=\"cRVSd\"]/span')\n",
    "            md = date.text.split(\"review\")[1].strip()\n",
    "\n",
    "            # Grab contributions and helpful vote\n",
    "            element = block.find_element(By.XPATH, './/div[@class=\"MziKN\"]')\n",
    "            text = element.text\n",
    "\n",
    "            # 使用正則表達式來提取數字部分\n",
    "            contributions_match = re.search(r'(\\d+)\\s*contributions', text)\n",
    "            helpful_vote_match = re.search(r'(\\d+)\\s*helpful votes', text)\n",
    "\n",
    "            # 提取 contributions 數字\n",
    "            if contributions_match:\n",
    "                contributions = int(contributions_match.group(1))\n",
    "            else:\n",
    "                contributions = 0\n",
    "            \n",
    "            # 提取 helpful vote 數字\n",
    "            if helpful_vote_match:\n",
    "                helpful_vote = int(helpful_vote_match.group(1))\n",
    "            else:\n",
    "                helpful_vote = 0\n",
    "\n",
    "                # 在每個評論區塊元素中尋找評分、標題和評論\n",
    "\n",
    "            # Grab rating\n",
    "            rating = block.find_element(By.XPATH, \".//span[contains(@class, 'ui_bubble_rating bubble_')]\").get_attribute(\"class\").split(\"_\")[3] # get_attribute(\"class\") mean \n",
    "\n",
    "            # Grab title\n",
    "            title = block.find_element(By.XPATH, \".//div[@data-test-target='review-title']\").text\n",
    "\n",
    "            # Grab review_content \n",
    "            review = block.find_element(By.XPATH, './/span[@class=\"QewHA H4 _a\"]/span').text.replace(\"\\n\", \"  \")\n",
    "            \n",
    "            # Grab trip and date type\n",
    "            trip_date_element = block.find_elements(By.XPATH, './/div[@class=\"vTVDc\"]//span')\n",
    "            # Initialize trip_type and date as 'NULL'\n",
    "            trip_type = 'NULL'\n",
    "            date_of_stay = 'NULL'\n",
    "            # Loop through each span element and check for the class\n",
    "            for span_element in trip_date_element:\n",
    "                if 'TDKzw _R Me' in span_element.get_attribute('class'):\n",
    "                    trip_type = block.find_element(By.XPATH, './/span[@class=\"TDKzw _R Me\"]').text.split(\":\")[1].strip()\n",
    "                    break  # Found the trip type, no need to continue searching\n",
    "            # print(trip_type)\n",
    "            \n",
    "            for span_element in trip_date_element:\n",
    "                if 'teHYY _R Me S4 H3' in span_element.get_attribute('class'):\n",
    "                    date_of_stay = block.find_element(By.XPATH, './/span[@class=\"teHYY _R Me S4 H3\"]').text.split(\":\")[1].strip()\n",
    "            # print(date_of_stay)\n",
    "            \n",
    "            # Grab review helpful vote\n",
    "            try:\n",
    "                rhv = block.find_element(By.XPATH, './/span[@class=\"hVSKz S2 H2 Ch sJlxi\"]')\n",
    "                \n",
    "                review_helpful_votes = rhv.text.split(' ')[0]\n",
    "            except: \n",
    "                review_helpful_votes = 0\n",
    "            \n",
    "            entry = {\n",
    "                \"Hotel_locID\" : loc,\n",
    "                \"Hotel_geoID\" : geo,\n",
    "                \"Review_id\": review_id,\n",
    "                \"Review_Date\": md,\n",
    "                \"Date_of_stay\": date_of_stay,\n",
    "                \"Reviewer_Contributions\": contributions,\n",
    "                \"Reviewer_helpful_vote\": helpful_vote,\n",
    "                \"Review_Rating\": rating,\n",
    "                \"Trip_type\": trip_type,\n",
    "                \"Review_helpful_votes\" : review_helpful_votes,\n",
    "                \"Title\": title,\n",
    "                \"Review\": review\n",
    "            }\n",
    "            row_data.append(entry)\n",
    "        \n",
    "        # 翻頁至下一頁，但最後一頁不翻頁\n",
    "        if i != pages_to_scrape-1:\n",
    "            driver.find_element(By.XPATH, '//a[@class=\"ui_button nav next primary \"]').click()\n",
    "\n",
    "    return row_data\n",
    "\n",
    "    # 完成所有頁面爬取後，關閉瀏覽器\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90777bb",
   "metadata": {},
   "source": [
    "## Run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9033d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 讀檔\n",
    "# csvFile = open('TA_review_0808.csv', 'a', encoding=\"utf-8\")\n",
    "# csvWriter = csv.writer(csvFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ed4e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取hotel review url list\n",
    "def get_hotels_list(start, end):\n",
    "    hotel_data_read=np.load('/home/hao/Code/variable/hotel_data_la_store.npy', allow_pickle=True)\n",
    "    hotel_data=hotel_data_read.tolist()\n",
    "    hotels_list = []\n",
    "    for h in hotel_data:\n",
    "        hotels_list.append('https://www.tripadvisor.com'+h['Url'])\n",
    "        \n",
    "    # 一次只處理一個範圍內的飯店\n",
    "    # start - end(不含end)\n",
    "        \n",
    "    hotels_list = hotels_list[start:end]\n",
    "    return hotels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd5710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_hotels_list(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e8f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 隨機抽取五筆\n",
    "# hotel_data_random = random.sample(hotel_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1506253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start, end): # parallel running\n",
    "    df = pd.DataFrame(columns=[\"Hotel_locID\", \"Hotel_geoID\", \"Review_id\", \"Review_Date\", \"Date_of_stay\", \"Reviewer_Contributions\", \"Reviewer_helpful_vote\", \"Review_Rating\", \"Trip_type\", \"Review_helpful_votes\"  ,\"Title\", \"Review\"])\n",
    "\n",
    "    hotels_list = get_hotels_list(start, end)\n",
    "    print(\"Hotel list length is \"+str(len(hotels_list)))\n",
    "    \n",
    "    driver = web_driver_setting()\n",
    "    # traversal all hotels' url\n",
    "    for hotel_url in tqdm(hotels_list):\n",
    "        try:\n",
    "            data = get_hotel_review(driver, hotel_url)\n",
    "            df = pd.concat([df, pd.DataFrame(data)])\n",
    "        except Exception as e:\n",
    "            f = Path('error_info_TA_review.txt').open('a')\n",
    "            f.write(\"Hotel URL: \"+ hotel_url + \"\\n\" + \"Error info: \" + str(e) + \"\\n\")\n",
    "            f.close()\n",
    "            print(e)\n",
    "            continue\n",
    "        \n",
    "    f = Path('error_info_TA_review.txt').open('a')\n",
    "    ftime = time.strftime(\"%Y-%m-%d %I:%M:%S %p\", time.localtime())\n",
    "    f.write(\"FINISH!!!!!!!!!! \" + ftime + \"\\n\")\n",
    "    f.close()\n",
    "    # df.to_csv(f\"result_csv/TA_review_{start}_to_{end}.csv\", index=False)\n",
    "    df.to_csv(f\"result_csv/TA_review_LA_{ftime}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63917c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hotel_data_read=np.load('/home/hao/Code/variable/hotel_data_store.npy', allow_pickle=True)\n",
    "# hotel_data=hotel_data_read.tolist()\n",
    "# hotels_list = []\n",
    "# for h in hotel_data:\n",
    "#     hotels_list.append('https://www.tripadvisor.com'+h['Url'])\n",
    "    \n",
    "# len(hotels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0adc0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel list length is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:12<00:00, 96.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# 一次只處理一個範圍內的飯店\n",
    "# start - end(不含end), main(start, end(不含))\n",
    "main(0, 503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a67b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
